{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# %%\nimport pandas as pd\nimport numpy as np\n\ndf_train = pd.read_csv('C:/Users/tetiana.lem/Desktop/Exploring Mental Health Data/Backpack/train.csv')\ndf_test = pd.read_csv('C:/Users/tetiana.lem/Desktop/Exploring Mental Health Data/Backpack/test.csv')\n\ndf_train = df_train.set_index('id')\ndf_test = df_test.set_index('id')  \nprint(df_train.isna().sum())\nprint(df_train.head())\nprint(df_train.shape[0])\n\n# %%\nmissing_labels = [-1, '-1', 'None', np.nan, '', '-', None, 'nan', pd.NaT, '<NA>', pd.NA]\nunique_values = {}\nfor col in df_train.columns:\n    missing_vals = df_train[col][df_train[col].isin(missing_labels)].unique().tolist()\n    non_missing_vals = df_train[col][~df_train[col].isin(missing_labels)].unique().tolist()\n    unique_values[col] = missing_vals + non_missing_vals\n\nunique_values = pd.DataFrame({\n    \"Column\": list(unique_values.keys()),\n    \"Unique Values\": [', '.join(map(str, v)) for v in unique_values.values()]  # Join the list as a string\n})\nunique_values\n\n# %%\ndf_train.replace(missing_labels, -1, inplace=True)\ndf_test.replace(missing_labels, -1, inplace=True)\n\n\n# %%\ndf_train.shape[0]\n\ndf_train = df_train[0:50000]\n\n# %%\ncategorical_cols = ['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n\ndf_train = pd.get_dummies(df_train, columns=categorical_cols, drop_first=True)\n\n\n# %%\ndf_test = pd.get_dummies(df_test, columns=categorical_cols, drop_first=True)\n\n# Show columns in df_test but not in df_train\ndiff_columns = set(df_test.columns) - set(df_train.columns)\nprint(\"Columns in df_test but not in df_train:\", diff_columns)\n\n\n# %%\ncols_to_exclude = ['Price', 'Weight Capacity (kg)']\n\n# Convert all columns except 'price' and 'weight' to integers in df_train\ndf_train.loc[:, ~df_train.columns.isin(cols_to_exclude)] = df_train.loc[:, ~df_train.columns.isin(cols_to_exclude)].astype(int)\n\n# Convert all columns except 'price' and 'weight' to integers in df_test\ndf_test.loc[:, ~df_test.columns.isin(cols_to_exclude)] = df_test.loc[:, ~df_test.columns.isin(cols_to_exclude)].astype(int)\n\n\n# %%\nimport pandas as pd\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\ntarget = 'Price'  # Replace with actual target column\nX_train = df_train.drop(columns=[target])\ny_train = df_train[target]\nX_test = df_test\n\n\n# %%\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Train the Support Vector Machine model\nsvr = SVR(kernel='rbf')\n\nsvr.fit(X_train, y_train)\n\n\n# %%\ny_pred = svr.predict(X_train)\n# Calculate RMSE\nrmse = np.sqrt(mean_squared_error(y_train, y_pred))\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\n\n\n# %%\ndf_test['predicted_price'] = svr.predict(X_test)\n\n\n# %%\ndf_test['predicted_price'].to_csv('submission.csv', index=True)\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}